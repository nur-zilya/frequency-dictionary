{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "W9CpykbyNM3q"
      },
      "outputs": [],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "import nltk\n",
        "nltk.download ('punkt')\n",
        "from nltk.tokenize import word_tokenize\n",
        "!pip uninstall spacy -y \n",
        "!pip install -U spacy>=3.0\n",
        "!python -m spacy download ru_core_news_md\n",
        "import spacy\n",
        "nlp = spacy.load('ru_core_news_md')\n",
        "# !pip install natasha"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "path ='/content/drive/MyDrive/second.txt' \n",
        "text = open(path, encoding='utf-8').read()\n",
        "import re\n",
        "text = re.sub('VII', '', text)\n",
        "text = re.sub('VIII', '', text)\n",
        "text = re.sub('XII', '', text)\n",
        "text = re.sub('XIII', '', text)\n",
        "text = re.sub('XIIв', '', text)\n",
        "text = re.sub('XIV', '', text)\n",
        "text = re.sub('XIX', '', text)\n",
        "text = re.sub('XVI', '', text)\n",
        "text = re.sub('XVII', '', text)\n",
        "text = re.sub('XVIII', '', text)\n",
        "text = re.sub('XVв', '', text)\n",
        "\n",
        "document = nlp(text)\n",
        "outname = path.replace('.txt', '-lemm.txt') \n",
        "with open(outname, 'w', encoding='utf8') as out:\n",
        "    for token in document:\n",
        "        out.write(token.lemma_.lower())\n",
        "        out.write(' ')"
      ],
      "metadata": {
        "id": "gMjyym7jOHGe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "path_lemms = '/content/drive/MyDrive/second-lemm.txt'\n",
        "to_read = open(path_lemms, encoding='utf-8').read()\n",
        "doc = nlp(to_read)"
      ],
      "metadata": {
        "id": "ZgAPvptqOXEA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ners = {}\n",
        "for token in doc:\n",
        "    ners[token.text] = token.ent_type_\n",
        "ners\n"
      ],
      "metadata": {
        "id": "Qj4LatlJOqxj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "PER = []\n",
        "for key, val in ners.items():\n",
        "  if ners[key] == 'PER':\n",
        "    PER.append(key)\n"
      ],
      "metadata": {
        "id": "sbfFkTDpSe6D"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tokens = nltk.word_tokenize(to_read)\n",
        "\n",
        "filtered_tokens = []\n",
        "\n",
        "for token in tokens:\n",
        "  if token not in PER:\n",
        "    filtered_tokens.append(token)\n",
        "# print (filtered_tokens)\n",
        "\n",
        "# print(len(tokens) , len(filtered_tokens))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AtXiLIy_TBFW",
        "outputId": "11a93e2d-4793-4d22-cc5d-7fd19c065b81"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "60343 56921\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "nltk.download('stopwords')\n",
        "from nltk.corpus import stopwords\n",
        "stop_words = stopwords.words('russian')\n",
        "stop_words.extend(['этот','весь','для','было','стать','что','был', 'была','это', 'свой','как', 'его', 'только','тот', 'однако', 'под', 'также', 'который', 'тыс','как', 'на', 'по' ])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XaBGC-XYTW_D",
        "outputId": "70a0273c-9bcb-4abb-de48-1c31ea483d81"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "filtered_stops_tokens = []\n",
        "for token in filtered_tokens:\n",
        "  if token not in stop_words:\n",
        "    filtered_stops_tokens.append(token)\n",
        "print (filtered_stops_tokens)"
      ],
      "metadata": {
        "id": "KTp3UAKoTZ5j"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "lema=[w for w in filtered_stops_tokens if w.isalpha() and len(w)>2]"
      ],
      "metadata": {
        "id": "x_kVX5shTifT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk import FreqDist\n",
        "freq = nltk.FreqDist(lema)\n",
        "fdist = FreqDist(lema)\n",
        "print(fdist.most_common(50)) \n"
      ],
      "metadata": {
        "id": "X51yNJsnTj66"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dictionary = dict(fdist)\n",
        "type(dictionary)\n",
        "dictionary"
      ],
      "metadata": {
        "id": "eEIVfxO3Tnk7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sorted_dict = dict(sorted(dictionary.items(), key=lambda item: item[1]))\n",
        "\n",
        "sorted_dict"
      ],
      "metadata": {
        "id": "2KTP_YnRTqCD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "with open('for_ex.txt', 'a', encoding='utf8') as out:\n",
        "    for key, value in sorted_dict.items():\n",
        "      out.write(key+','+str(value)+'\\n')\n"
      ],
      "metadata": {
        "id": "HDhS8OOSTryr"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}